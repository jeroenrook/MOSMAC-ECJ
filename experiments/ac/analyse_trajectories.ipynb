{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import itertools\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pygmo\n",
    "from pymoo.indicators.igd_plus import IGDPlus\n",
    "from datetime import datetime\n",
    "import time\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import scenarios as scenariodef\n",
    "from multiprocess import Pool\n",
    "# import configurators\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "resultdir = Path(\"results_full\")\n",
    "figurepath = Path(\"figures\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "configurators = [\"RandomSearch\", \"RandomSearchSI\", \"RandomSearch25\", \"default\",  \"SMAC\", \"MO-ParamILS\",  \"ParEGO\", \"MO-SMAC\", \"MO-SMAC-PHVI\"]\n",
    "\n",
    "# color_palette = [(230, 159, 0), (86, 180, 233), (0, 158, 115), (240, 228, 66), (0, 114, 178), (213, 94, 0), (204, 121, 167)]  # Wong color palette (works for color-blinded people)\n",
    "color_palette = [(51, 34, 136), (17, 119, 51), (68, 170, 156), (136, 204, 238), (221, 204, 119), (204, 102, 119), (170, 68, 153), (136, 34, 85),][::-1]  # Tol colorblind palette (https://davidmathlogic.com/colorblind/#%23332288-%23117733-%2344AA99-%2388CCEE-%23DDCC77-%23CC6677-%23AA4499-%23882255)\n",
    "color_palette = [tuple([float(f\"{channel / 255:.3f}\") for channel in color]) for color in color_palette]\n",
    "color_palette += color_palette\n",
    "# color_palette = sns.color_palette(palette=\"colorblind\")\n",
    "markers = [\"s\", \"o\", \"X\", \"P\", \"^\", \"v\", \">\", \"<\", \"*\"][::-1]\n",
    "\n",
    "\n",
    "\n",
    "def get_style(conf, key):\n",
    "    return style_guide[conf][key]\n",
    "\n",
    "# display(style_guide)\n",
    "\n",
    "config_names = {\n",
    "    \"MO-SMAC-PHVI\": \"MO-SMAC-PHVI\",\n",
    "    \"ParEGO\":  \"MO-SMAC-PE\",\n",
    "    \"MO-SMAC\": \"MO-SMAC-EHVI\",\n",
    "    \"MO-ParamILS\": \"MO-ParamILS\",\n",
    "    \"SMAC\": \"SMAC\",\n",
    "    \"RandomSearchSI\": \"Random Search + MO-Intensify\",\n",
    "    \"RandomSearch\": \"Random Search\",\n",
    "    \"RandomSearch25\": \"Random Search\",\n",
    "    \"default\": \"Default\",\n",
    "}\n",
    "reverse_config_names = {v: k for k, v in config_names.items()}\n",
    "\n",
    "style_guide = {}\n",
    "for i, conf in enumerate(config_names.values()):\n",
    "    style_guide[conf] = {\"color\": color_palette[i%len(color_palette)], \"marker\": markers[i%len(markers)]}\n",
    "\n",
    "print(style_guide)\n",
    "\n",
    "# import matplotlib\n",
    "# matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "# matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# #matplotlib.use(\"pgf\")\n",
    "# matplotlib.rcParams.update({\n",
    "#     #\"pgf.texsystem\": \"pdflatex\",\n",
    "#     'font.family': 'serif',\n",
    "#     # 'text.usetex': True,\n",
    "#     # 'pgf.rcfonts': False,\n",
    "# })\n",
    "\n",
    "scenario_replacements = {\n",
    "    \"EA_OO_MMMOOP\": \"EMOA-(hv, sp)\",\n",
    "    \"MIP_CPLEX_REGIONS200_cutoff\": \"MIP-(gap, cutoff)\",\n",
    "    \"MIP_CPLEX_REGIONS200_runtime\": \"MIP-(gap, runtime)\",\n",
    "    \"MIP_CPLEX_REGIONS200_CONT_cutoff\": \"MIP-(gap, cutoff) (c)\",  # (c)\n",
    "    \"MIP_CPLEX_REGIONS200_CONT_runtime\": \"MIP-(gap, runtime) (c)\",  # (c)\n",
    "    \"SAT_CMS_QUEENS_runtime_memory\": \"SAT-(runtime, memory)\",\n",
    "    \"SAT_CMS_QUEENS_runtime_solved\": \"SAT-(runtime, solved)\",\n",
    "    \"SAT_ganak_DQMR_runtime_memory\": \"#SAT-(runtime, solved)\",\n",
    "    \"ML_RF_STUDENTS_precision_recall\": \"ML-(precision, recall)\",\n",
    "    \"ML_RF_STUDENTS_precision_recall_size\": \"ML-(precision, recall, size)\",\n",
    "    \"ML_RF_STUDENTS_accuracy_size\": \"ML-(accuracy, size)\",\n",
    "}\n",
    "\n",
    "reverse_scenario_replacements = {v: k for k, v in scenario_replacements.items()}\n",
    "\n",
    "configurator_replacements = config_names\n",
    "\n",
    "palette = {conf: col for conf, col in zip(config_names.values(), color_palette)}\n",
    "markers = {conf: col for conf, col in zip(config_names.values(), markers)}\n",
    "order = configurators  #  [conf for conf in list(config_names.keys()) if conf in list(qdf[\"configurator\"].unique())]\n",
    "\n",
    "\n",
    "def rename_metadata(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for k, v in scenario_replacements.items():\n",
    "        df.loc[df[\"scenario\"] == k, \"scenario\"] = v\n",
    "    for k, v in configurator_replacements.items():\n",
    "        df.loc[df[\"configurator\"] == k, \"configurator\"] = v\n",
    "    return df\n",
    "\n",
    "print(f\"{config_names=}\")\n",
    "print(f\"{palette=}\")\n",
    "print(f\"{markers=}\")\n",
    "\n",
    "textwidth = 404 * 2.4# pt\n",
    "pt_per_in = 0.0138888889 \n",
    "textwidth_in = textwidth * pt_per_in\n",
    "n_figs_per_row = 4.25\n",
    "figwidth = textwidth_in / n_figs_per_row\n",
    "figsize = (figwidth, figwidth * 0.8)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7637a6364dc6288",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Performance results\n",
    "Configuration procedure:\n",
    "- Run a configurator $n$ times on a scenario with a different random seed.\n",
    "- Validate the final incumbent (single or multiple configurations) of each configuration run on a common validation set (subset of the train set).\n",
    "- Combine all the incumbents into one archive and throw out all the dominated configurations. This configuration in the archive are non-dominated.\n",
    "- Validate configurations in the filtered archive on the training set.\n",
    "\n",
    "HV computation:\n",
    "- Determine reference point by choosing the largest obtained mean value for an objective by all validation and training runs of all configurations found by all configurators.\n",
    "- Compute the HV.\n",
    "\n",
    "## Dataloading"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e3982c06f5807a8"
  },
  {
   "cell_type": "code",
   "source": [
    "scenario_files = [d for d in resultdir.joinpath(\"collecttraj\").iterdir()]\n",
    "scenarios = []\n",
    "for i, s in enumerate(scenario_files):\n",
    "    print(Path(s).name)\n",
    "    dfpath = f\"{resultdir}/collecttraj/dataframes/{Path(s).name}.csv\"\n",
    "    metapath = f\"{resultdir}/collecttraj/metadata/{Path(s).name}.json\"\n",
    "    finalincpicklepath = f\"{resultdir}/collect/{Path(s).name}\"     \n",
    "\n",
    "    loaded_from_csv: bool = False\n",
    "    try:\n",
    "        with open(s, \"rb\") as fh:\n",
    "            scenario = pickle.load(fh)\n",
    "    except:\n",
    "        # try json and csv\n",
    "        if not (Path(dfpath).exists() and Path(metapath).exists()):\n",
    "            print(f\"Couldn't load {s}\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(dfpath)\n",
    "        loaded_from_csv = True\n",
    "        with open(metapath, \"r\") as f:\n",
    "            scenario = json.load(f)\n",
    "\n",
    "        scenario[\"run_result\"] = df\n",
    "        pass\n",
    "    \n",
    "    scenario_name = str(scenario['experiment'][\"scenarios\"])\n",
    "    scen = getattr(scenariodef, scenario_name)()\n",
    "    objectives = [o[\"name\"] for o in scen.objectives]\n",
    "\n",
    "    if scenario[\"experiment\"][\"scenarios\"] in [\"MIP_CPLEX_REGIONS200_CONT_cutoff\",\n",
    "                                               \"MIP_CPLEX_REGIONS200_CONT_runtime\",\n",
    "                                               \"SAT_CMS_QUEENS_runtime_memory\",\n",
    "                                               \"SAT_ganak_DQMR_runtime_memory\",\n",
    "                                               \"ML_RF_STUDENTS_precision_recall\",\n",
    "                                               \"ML_RF_STUDENTS_precision_recall_size\",\n",
    "                                               \"ML_RF_STUDENTS_accuracy_size\",\n",
    "                                               \"EA_OO_MMMOOP\"\n",
    "                                               ]:\n",
    "        df = scenario[\"run_result\"]\n",
    "        print(f\"{df['configurators'].unique()=}\")\n",
    "        df = df[~df[\"configurators\"].isin([\"MO-SMAC\", \"RandomSearchSI\",\"RandomSearch\"])]\n",
    "        \n",
    "        #Load final incumbent and load trajectories\n",
    "        with open(finalincpicklepath, \"rb\") as fh:\n",
    "            finalincresults = pickle.load(fh)\n",
    "        fdf = finalincresults[\"run_result\"]\n",
    "        fdf = fdf[~fdf[\"configurators\"].isin([\"MO-SMAC\", \"RandomSearchSI\",\"RandomSearch\"])]\n",
    "        fdf[\"seeds\"] = fdf[\"seeds\"].astype(int)\n",
    "        fdf = fdf[fdf[\"seeds\"] <  20]\n",
    "        keys = [\"scenarios\", \"configurators\", \"seeds\"]\n",
    "        for crun, grp in fdf.groupby(keys):\n",
    "            keyvals = crun\n",
    "            crun = list(crun)\n",
    "            crun[0] = crun[0].replace(\"_\",\"-\")\n",
    "            configurepath = resultdir / \"configure\" / (\"_\".join([str(c) for c in crun])+\".pickle\")\n",
    "            if not configurepath.exists():\n",
    "                continue\n",
    "            \n",
    "            with open(configurepath, \"rb\") as fh:\n",
    "                configdata = pickle.load(fh)\n",
    "            \n",
    "            if keyvals[1] == \"SMAC\":\n",
    "                last_incumbent = [traj[\"trajectory\"][-1][\"config_ids\"][0] for traj in configdata[\"run_result\"][\"trajectory\"]]\n",
    "                actual_config_ids = {str(k): f\"{k}_{v}\" for k, v in enumerate(last_incumbent)}\n",
    "            elif keyvals[1] == \"default\":\n",
    "                last_incumbent = configdata[\"run_result\"][\"trajectory\"][-1][\"config_ids\"]\n",
    "                actual_config_ids = {str(k): str(v) for k, v in enumerate(last_incumbent)} \n",
    "            else:\n",
    "                last_incumbent = configdata[\"run_result\"][\"trajectory\"][\"trajectory\"][-1][\"config_ids\"]\n",
    "                actual_config_ids = {str(k): str(v) for k, v in enumerate(last_incumbent)} \n",
    "            \n",
    "            mask = [fdf[k] == v for k, v in zip(keys, keyvals)]\n",
    "            mask = [all(row) for row in zip(*mask)]\n",
    "            fdf.loc[mask, \"configuration\"] = fdf.loc[mask, \"configuration\"].replace(actual_config_ids)\n",
    "\n",
    "        df[\"seeds\"] = df[\"seeds\"].astype(int)\n",
    "        print(\"seeds\", list(df[\"seeds\"].unique()))\n",
    "\n",
    "        df = df[df[\"seeds\"] <  20]\n",
    "        \n",
    "        print(f\"{len(df)=}\")\n",
    "        df = pd.concat([df, fdf], ignore_index=True)\n",
    "        print(f\"{len(df)=}\")\n",
    "        \n",
    "        df[\"action\"] = df[\"action\"].replace({\"testtraj\": \"test\", \"validatetraj\":\"validate\"})\n",
    "        df[\"configid\"] = [(r[\"seeds\"], r[\"configuration\"]) for _,r in df.iterrows()]\n",
    "        df.loc[df[\"status\"] == \"CRASHED\", objectives] = df[df[\"status\"] != \"CRASHED\"][objectives].max().to_numpy()\n",
    "        \n",
    "        scenario_name = str(scenario['experiment'][\"scenarios\"])\n",
    "        scen = getattr(scenariodef, scenario_name)()\n",
    "        objectives = [o[\"name\"] for o in scen.objectives]\n",
    "        scenario[\"objectives\"] = objectives\n",
    "        df = df.groupby([\"scenarios\", \"action\", \"seeds\", \"configurators\", \"configuration\", \"configid\"])[objectives].mean().reset_index()\n",
    "        print(f\"{df[df.isna().any(axis=1)]=}\")\n",
    "        print(f\"{len(df)=}\")\n",
    "        \n",
    "        #Normalize and compute reference set\n",
    "        stats_dest = Path(f\"intermediates/norm_stats/{scenario_name}.csv\")\n",
    "        if stats_dest.exists():\n",
    "            stats = pd.read_csv(stats_dest, index_col=[0, 1])\n",
    "            print(f\"Got normalisation stats from file {stats_dest}\")\n",
    "        else:\n",
    "            stats = df.groupby(\"action\")[objectives].describe().stack()\n",
    "\n",
    "        reference_set = dict()\n",
    "        igdp = dict()\n",
    "        \n",
    "        #Normalize objectives\n",
    "        for a in [\"test\", \"validate\"]:\n",
    "            for o in objectives:\n",
    "                df.loc[df[\"action\"] == a, o+\"_norm\"] = 1 + ((df.loc[df[\"action\"] == a, o] - stats.loc[(a,\"min\"), o]) / (stats.loc[(a,\"max\"), o] - stats.loc[(a,\"min\"), o])).clip(0, 1)\n",
    "                \n",
    "            points = df.loc[df[\"action\"] == a, [o+\"_norm\" for o in objectives]].to_numpy()\n",
    "            refset_ids = pygmo.fast_non_dominated_sorting(points)[0][0]\n",
    "            refset = points[refset_ids, :]\n",
    "            reference_set[a] = refset.tolist()\n",
    "        \n",
    "        scenario[\"reference_set\"] = reference_set\n",
    "        scenario[\"reference_point\"] = [2.0+1e-1] * len(objectives)\n",
    "        \n",
    "        scenario[\"run_result\"] = df\n",
    "        scenarios.append(scenario)\n",
    "\n",
    "        #export\n",
    "        for p in [dfpath, metapath]:\n",
    "            Path(p).parent.mkdir(parents=True, exist_ok=True )\n",
    "        df = scenario[\"run_result\"]\n",
    "        if not loaded_from_csv:\n",
    "            df.to_csv(dfpath, index=False)\n",
    "        meta_data = copy.copy(scenario)\n",
    "        del meta_data[\"run_result\"]\n",
    "        with open(metapath, \"w\") as f:\n",
    "            json.dump(meta_data, f)\n",
    "\n",
    "print(f\"Got {len(scenarios)} scenarios\")\n",
    "\n",
    "for scenario in scenarios:\n",
    "    for k, v in scenario_replacements.items():\n",
    "        scenario[\"run_result\"].loc[scenario[\"run_result\"][\"scenarios\"] == k, \"scenarios\"] = v\n",
    "    for k, v in configurator_replacements.items():\n",
    "        scenario[\"run_result\"].loc[scenario[\"run_result\"][\"configurators\"] == k, \"configurators\"] = v\n",
    "    \n",
    "\n",
    "scenarios = sorted(scenarios, key=lambda s: s[\"experiment\"][\"scenarios\"])  # Sort by name\n",
    "[s[\"experiment\"][\"scenarios\"] for i, s in enumerate(scenarios)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4018ee854ca95ec4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df[df[\"configurators\"] == \"SMAC\"]\n",
    "df[\"configurators\"].unique()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ccc4d6042f4f895",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trajectory plots\n",
    "\n",
    "## Metric calculation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b173c1c1850b2ed"
  },
  {
   "cell_type": "code",
   "source": [
    "# Helper functions\n",
    "def compute_hypervolume(configurations, df: pd.DataFrame, objectives, reference_point, action=\"validate\") -> float:\n",
    "    df = df[df[\"action\"] == action]\n",
    "    points = df[df[\"configid\"].isin(configurations)][objectives].to_numpy()\n",
    "    return pygmo.hypervolume(points).compute(reference_point)\n",
    "\n",
    "def compute_igdp(configurations, df: pd.DataFrame, objectives, refset, action=\"validate\"):\n",
    "    igdp = IGDPlus(np.array(refset))\n",
    "    df = df[df[\"action\"] == action]\n",
    "    points = df[df[\"configid\"].isin(configurations)][objectives].to_numpy()\n",
    "    return igdp(points)\n",
    "\n",
    "def get_nd_configurations(configurations: list[tuple], df, objectives, action=\"validate\") -> list[int]:\n",
    "    # Get performance on validate set\n",
    "    df = df[df[\"action\"] == action]\n",
    "    df = df[df[\"configid\"].isin(configurations)]\n",
    "    points = df[objectives].to_numpy()\n",
    "    configids = list(df[\"configid\"])\n",
    "    \n",
    "    if len(points) == 1:\n",
    "        return configids\n",
    "    else:\n",
    "        ndp = pygmo.fast_non_dominated_sorting(points)[0][0]\n",
    "        return [configids[i] for i in ndp]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f0ab7a167319d18",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trajectory gathering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4116d0f66fdc9e8f"
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_meta_trajectory(trajectories: dict[int, dict]) -> dict:\n",
    "    \"\"\"\n",
    "    Compute the trajectory for from multiple configuration run trajectories.\n",
    "    \"\"\"\n",
    "    \n",
    "    meta_trajectory = {}\n",
    "    last_event = None\n",
    "    events = [[k for k, _ in t.items()] for _, t in trajectories.items()]\n",
    "    traj_keys = [k for k in trajectories.keys()]\n",
    "    pointers = np.zeros(len(events), dtype=int)\n",
    "    \n",
    "    while np.count_nonzero(pointers >= 0) > 0:\n",
    "        # Find next trajectory change\n",
    "        next_change = np.argmin([events[s][k] if k >= 0 else np.inf for s, k in enumerate(pointers)])\n",
    "        event_time = events[next_change][pointers[next_change]]\n",
    "        \n",
    "        new_state = [] if last_event is None else copy.copy(meta_trajectory[last_event])\n",
    "        \n",
    "        # Remove old state from the respective trajectory run\n",
    "        new_state = [c for c in new_state if c[0] != traj_keys[next_change]]\n",
    "        \n",
    "        # Add new state from the respective trajectory run   \n",
    "        configurations = trajectories[traj_keys[next_change]][event_time]\n",
    "        new_state += [(traj_keys[next_change], c) for c in configurations]\n",
    "\n",
    "        meta_trajectory[event_time] = new_state\n",
    "\n",
    "        # Update pointer\n",
    "        pointers[next_change] += 1\n",
    "        if pointers[next_change] == len(events[next_change]):\n",
    "            pointers[next_change] = -1\n",
    "            \n",
    "        # Update last time\n",
    "        last_event = event_time\n",
    "        \n",
    "    return meta_trajectory\n",
    "\n",
    "\n",
    "def get_trajectory_from_file(scenario, configurator, seed):\n",
    "    scenario = reverse_scenario_replacements[scenario]\n",
    "    scenario = scenario\n",
    "    \n",
    "    configurator = reverse_config_names[configurator]\n",
    "    \n",
    "    configurepath = resultdir / \"configure\" / f\"{scenario.replace('_','-')}_{configurator}_{seed}.pickle\"\n",
    "    if not configurepath.exists():\n",
    "        print(f\" {configurepath} does not exist\")\n",
    "        return\n",
    "    \n",
    "    with open(configurepath, \"rb\") as fh:\n",
    "        configdata = pickle.load(fh)\n",
    "\n",
    "    if configurator == \"SMAC\":\n",
    "        \n",
    "        #SO procedure cutoff needs to be adjusted to represent the full budget again.\n",
    "        scen = getattr(scenariodef, scenario)()\n",
    "        if \"MIP\" in scenario:\n",
    "            corr_factor = [sum(scen.cutoffs)/c for c in scen.cutoffs]\n",
    "        else:\n",
    "            corr_factor = [len(scen.objectives)]*len(scen.objectives)\n",
    "        \n",
    "        trajectories = {}\n",
    "        for i, traj in enumerate(configdata[\"run_result\"][\"trajectory\"]):\n",
    "            if i >= len(corr_factor):\n",
    "                # print(f\"More runs found than objectives in {scenario} for {configurator}\")\n",
    "                # REMOVES F1 from ML scenarios\n",
    "                break\n",
    "            trajectory = traj[\"trajectory\"]\n",
    "            trajectory = {t[\"walltime\"]*corr_factor[i]: [f\"{i}_{c}\" for c in t[\"config_ids\"]] for t in trajectory}\n",
    "            trajectories[i] = trajectory\n",
    "            \n",
    "        trajectory = compute_meta_trajectory(trajectories)\n",
    "        trajectory = {k: [c for _, c in v] for k, v in trajectory.items()}\n",
    "    elif configurator == \"default\":\n",
    "        trajectory = configdata[\"run_result\"][\"trajectory\"]\n",
    "        trajectory = {t[\"walltime\"]: [str(c) for c in t[\"config_ids\"]] for t in trajectory}\n",
    "    else:\n",
    "        trajectory = configdata[\"run_result\"][\"trajectory\"][\"trajectory\"]\n",
    "        trajectory = {t[\"walltime\"]: [str(c) for c in t[\"config_ids\"]] for t in trajectory}\n",
    "    return trajectory\n",
    "\n",
    "def get_all_trajectories_from_file(scenario, configurator):\n",
    "    trajectories = {}\n",
    "    for seed in range(20):\n",
    "        trajectories[seed] = get_trajectory_from_file(scenario, configurator, seed)\n",
    "    return trajectories"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "158fd926a42777f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "scenario = scenarios[0]\n",
    "scenario_name = str(scenario['experiment'][\"scenarios\"])\n",
    "print(scenario_name)\n",
    "scen = getattr(scenariodef, scenario_name)()\n",
    "objectives = [o[\"name\"] for o in scen.objectives]\n",
    "print(objectives)\n",
    "df = scenario[\"run_result\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87c90fe1df97c96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[df.isna().any(axis=1)]",
   "id": "9b34f1adb7af934b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "get_trajectory_from_file('MIP-(gap, cutoff) (c)', 'SMAC', 0)",
   "metadata": {
    "collapsed": false
   },
   "id": "ab647cf5d70f5d61",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "get_nd_configurations([(11, '0_1')], df, objectives)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a806dd157371a6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Compute reference data\n",
    "# Reference nadir point\n",
    "# Reference Pareto set\n",
    "# Normalisation bounds per objectives\n",
    "\n",
    "# stats = df.groupby(\"action\")[objectives].describe().stack()\n",
    "# \n",
    "# reference_set = dict()\n",
    "# igdp = dict()\n",
    "# \n",
    "# #Normalize objectives\n",
    "# for a in [\"test\", \"validate\"]:\n",
    "#     for o in objectives:\n",
    "#         df.loc[df[\"action\"] == a, o+\"_norm\"] = 1 + ((df.loc[df[\"action\"] == a, o] - stats.loc[(a,\"min\"), o]) / (stats.loc[(a,\"max\"), o] - stats.loc[(a,\"min\"), o]))\n",
    "#         \n",
    "#     points = df.loc[df[\"action\"] == a, [o+\"_norm\" for o in objectives]].to_numpy()\n",
    "#     refset_ids = pygmo.fast_non_dominated_sorting(points)[0][0]\n",
    "#     refset = points[refset_ids, :]\n",
    "#     reference_set[a] = refset\n",
    "#     igdp[a] = IGDPlus(refset)\n",
    "#         \n",
    "# reference_point = [2.0+1e-1]*len(objectives)\n",
    "# \n",
    "# reference_set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff0b9389af1b0e40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from joblib import Parallel, delayed",
   "id": "98801cff1bc307ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for scenario_id, scenario in enumerate(scenarios):\n",
    "    scenario_name = str(scenario['experiment'][\"scenarios\"])\n",
    "    print(scenario_name)\n",
    "    scen = getattr(scenariodef, scenario_name)()\n",
    "    objectives = scenario[\"objectives\"]\n",
    "    objectivesnorm = [o+\"_norm\" for o in objectives]\n",
    "    print(objectives)\n",
    "    \n",
    "    # trajdfpath = Path(f\"intermediates/sampled_trajectories/8runs_190samples_{scenario_name}.csv\")\n",
    "    trajdfpath = Path(f\"intermediates/sampled_trajectories/new_8runs_190samples_{scenario_name}.csv\")\n",
    "    \n",
    "    if trajdfpath.exists():\n",
    "        print(\"Getting samples from file\")\n",
    "        trajdf = pd.read_csv(str(trajdfpath))\n",
    "        trajdf = trajdf[trajdf[\"configurator\"] != \"Random Search\"]\n",
    "        trajdf[\"configurator\"].replace(\"Random Search 25\", \"Random Search\")\n",
    "        scenarios[scenario_id][\"trajectorydf\"] = trajdf\n",
    "        continue\n",
    "    \n",
    "    df = scenario[\"run_result\"]\n",
    "    keys = [\"scenarios\", \"configurators\"]\n",
    "    trajdf = []\n",
    "    # for crun, grp in df.groupby(keys):\n",
    "    #     print(crun)\n",
    "    #     # Get the trajectory from the configuration run\n",
    "    #     keyvals = crun\n",
    "    #     trajectories = get_all_trajectories_from_file(*crun)\n",
    "    #     rng = np.random.RandomState(42)\n",
    "    #     for i in tqdm(range(190)):\n",
    "    #         selected_seeds = rng.choice(20, 8, replace=False)\n",
    "    #         trajectory = compute_meta_trajectory({k: v for k,v in trajectories.items() if k in selected_seeds})\n",
    "    #         for wtime, perf in trajectory.items():\n",
    "    #             perf = get_nd_configurations(perf, df, objectives)\n",
    "    #             result_row = {\n",
    "    #                 \"configurator\": crun[1],\n",
    "    #                 \"permutation\": i,\n",
    "    #                 \"walltime\": wtime,\n",
    "    #                 \"hv_val\": compute_hypervolume(perf, df, objectivesnorm, scenario[\"reference_point\"], action=\"validate\"),\n",
    "    #                 \"hv_test\": compute_hypervolume(perf, df, objectivesnorm, scenario[\"reference_point\"], action=\"test\"),\n",
    "    #                 \"igdp_val\": compute_igdp(perf, df, objectivesnorm, scenario[\"reference_set\"][\"validate\"], action=\"validate\"),\n",
    "    #                 \"igdp_test\": compute_igdp(perf, df, objectivesnorm, scenario[\"reference_set\"][\"test\"], action=\"test\"),\n",
    "    #             }\n",
    "    #             trajdf.append(result_row)\n",
    "        \n",
    "    def process_permutation(i, crun, trajectories, df, objectives, objectivesnorm, scenario):\n",
    "        rng = np.random.RandomState(i)\n",
    "        selected_seeds = rng.choice(20, 8, replace=False)\n",
    "        trajectory = compute_meta_trajectory({k: v for k, v in trajectories.items() if k in selected_seeds})\n",
    "        local_results = []\n",
    "        for wtime, perf in trajectory.items():\n",
    "            perf = get_nd_configurations(perf, df, objectives)\n",
    "            result_row = {\n",
    "                \"configurator\": crun[1],\n",
    "                \"permutation\": i,\n",
    "                \"walltime\": wtime,\n",
    "                \"hv_val\": compute_hypervolume(perf, df, objectivesnorm, scenario[\"reference_point\"], action=\"validate\"),\n",
    "                \"hv_test\": compute_hypervolume(perf, df, objectivesnorm, scenario[\"reference_point\"], action=\"test\"),\n",
    "                \"igdp_val\": compute_igdp(perf, df, objectivesnorm, scenario[\"reference_set\"][\"validate\"], action=\"validate\"),\n",
    "                \"igdp_test\": compute_igdp(perf, df, objectivesnorm, scenario[\"reference_set\"][\"test\"], action=\"test\"),\n",
    "            }\n",
    "            local_results.append(result_row)\n",
    "        return local_results\n",
    "    \n",
    "    trajdf = []\n",
    "    for crun, grp in df.groupby(keys):\n",
    "        print(crun)\n",
    "        # Get the trajectory from the configuration run\n",
    "        keyvals = crun\n",
    "        trajectories = get_all_trajectories_from_file(*crun)\n",
    "    \n",
    "        num_permutations = 190\n",
    "        results = Parallel(n_jobs=6, )(\n",
    "            delayed(process_permutation)(i, crun, trajectories, df, objectives, objectivesnorm, scenario) for i in tqdm(range(num_permutations))\n",
    "        )\n",
    "    \n",
    "        trajdf += [row for result in results for row in result]\n",
    "        \n",
    "    trajdf = pd.DataFrame(trajdf)\n",
    "    \n",
    "    trajdfpath.parent.mkdir(exist_ok=True, parents=True)\n",
    "    trajdf.to_csv(str(trajdfpath))\n",
    "    scenarios[scenario_id][\"trajectorydf\"] = trajdf"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e40fd7776cb6b066",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[df.isna().any(axis=1)]",
   "id": "bf410b7e7eb125b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "palette[\"Random Search 25\"] = palette[\"Random Search\"]\n",
    "palette[\"Random Search (25)\"] = palette[\"Random Search\"]\n",
    "palette"
   ],
   "id": "1d812584437a67db",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sns.set(font_scale=1.)\n",
    "for scenario_id, scenario in enumerate(scenarios):\n",
    "    scenario_name = str(scenario['experiment'][\"scenarios\"])\n",
    "    print(scenario_name)\n",
    "    scen = getattr(scenariodef, scenario_name)()\n",
    "    objectives = scenario[\"objectives\"]\n",
    "    objectivesnorm = [o+\"_norm\" for o in objectives]\n",
    "    print(objectives)\n",
    "    hvdf = scenario[\"trajectorydf\"]\n",
    "    \n",
    "    flattened = []\n",
    "    \n",
    "    for timestep in tqdm(np.linspace(0, hvdf[\"walltime\"].max(), 128, dtype=int)):\n",
    "    # for timestep in tqdm(hvdf[\"walltime\"].astype(int).sort_values().unique()):  # point at every change\n",
    "        current_idx = hvdf[hvdf[\"walltime\"] <= timestep].groupby([\"configurator\", \"permutation\"])[\"walltime\"].idxmax()\n",
    "        fdf = copy.copy(hvdf.loc[current_idx].reset_index())\n",
    "        fdf[\"walltime\"] = timestep\n",
    "        flattened.append(fdf)\n",
    "            \n",
    "    flattened = pd.concat(flattened, ignore_index=True)\n",
    "        \n",
    "    for o in itertools.product([\"hv\", \"igdp\"], [\"val\", \"test\"]):\n",
    "        print(o)\n",
    "        target = \"_\".join(o)\n",
    "        fig, ax = plt.subplots(1, 1, figsize=figsize, dpi=300)\n",
    "        g = sns.lineplot(data=flattened, x=\"walltime\", y=target, hue=\"configurator\", palette=palette, ax=ax)\n",
    "        # g._legend.remove()\n",
    "        ax.get_legend().remove()\n",
    "        \n",
    "        # last_point = flattened.iloc[flattened.groupby(\"configurator\")[\"walltime\"].idxmax()]\n",
    "        # ax.scatter(last_point[\"walltime\"], last_point[target])\n",
    "        \n",
    "        # fig, ax = plt.subplots(1, 1, figsize=(4,3))\n",
    "        # for configurator, grp in flattened.groupby(\"configurator\"):\n",
    "        #     grp = grp.sort_values(\"walltime\")\n",
    "        #     x = grp[\"walltime\"].unique()\n",
    "        #     mean = grp.groupby(\"walltime\")[target].mean()\n",
    "        #     ax.plot(x, mean, label=configurator, color=style_guide[configurator][\"color\"], zorder=10)\n",
    "        #     std = grp.groupby(\"walltime\")[target].std()\n",
    "        #     ax.fill_between(x, mean - 0.25*std, mean + 0.25*std, alpha=0.25, color=style_guide[configurator][\"color\"], zorder=-10)\n",
    "        \n",
    "        limits = flattened.groupby([\"walltime\",\"configurator\"])[target].mean().reset_index()\n",
    "        limits = limits[limits[\"walltime\"] > limits[\"walltime\"].quantile(0.1)][target]\n",
    "        limits = (limits.min()*0.98, limits.max()*1.02)\n",
    "        print(f\"{limits}\")\n",
    "        ax.set_ylim(limits)\n",
    "        ax.set_xlabel(\"Walltime [seconds]\")\n",
    "        metric_names={\"hv\": \"Hypervolume\", \"igdp\": \"IGD+\"}\n",
    "        partition_names={\"val\": \"validation\", \"test\": \"test\"}\n",
    "        ax.set_ylabel(f\"{metric_names[o[0]]} ({partition_names[o[1]]})\")\n",
    "        ax.set_ylabel(f\"{metric_names[o[0]]}\")\n",
    "        ax.set_title(scenario_replacements[scenario_name].replace(\"(c)\",\"\"))\n",
    "        figurepathfile = Path(figurepath / f\"trajectories/{target}_{scenario_name}.pdf\")\n",
    "        figurepathfile.parent.mkdir(parents=True, exist_ok=True)\n",
    "        # if o[0] == \"hv\":\n",
    "        #     plt.ylim(1, 1.15)\n",
    "        # if o[0] == \"igdp\":\n",
    "        #     plt.ylim(0, 0.05)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(figurepathfile), bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        # plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1260d74eefa32d45",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# flattened[flattened[\"walltime\"] >= flattened[\"walltime\"].quantile(0.5)][\"hv_val\"].describe()\n",
    "flattened.iloc[flattened.groupby(\"configurator\")[\"walltime\"].idxmax()]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ef8a10d58f78f27",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for o in itertools.product([\"hv\", \"igdp\"], [\"val\", \"test\"]):\n",
    "    print(o)\n",
    "    target = \"_\".join(o)\n",
    "    # sns.lineplot(data=flattened, x=\"walltime\", y=target, hue=\"configurator\")\n",
    "    for configurator, grp in flattened.groupby(\"configurator\"):\n",
    "        grp = grp.sort_values(\"walltime\")\n",
    "        x = grp[\"walltime\"].unique()\n",
    "        plt.plot(x, grp.groupby(\"walltime\")[target].mean(), label=configurator, color=style_guide[configurator][\"color\"], zorder=10)\n",
    "        plt.fill_between(x, grp.groupby(\"walltime\")[target].quantile(0.05), grp.groupby(\"walltime\")[target].quantile(0.95), alpha=0.25, color=style_guide[configurator][\"color\"], zorder=-10)\n",
    "    plt.title(scenario_name+\" (runs=8)\")\n",
    "    limits = (flattened[target].quantile(0.05)*0.98, flattened[target].quantile(0.95)*1.02)\n",
    "    plt.ylim(limits)\n",
    "    plt.legend()\n",
    "    # figurepath = Path(figurepath / f\"trajectories/{target}_{scenario_name}.pdf\")\n",
    "    # figurepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "    # plt.savefig(str(figurepath))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fba7e3bb30d165",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9441cb46db4146b7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
